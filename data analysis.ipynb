{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give me some credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the input csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/cs-training.csv')\n",
    "test = pd.read_csv('data/cs-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "0           1                 1                              0.766127   45   \n",
       "1           2                 0                              0.957151   40   \n",
       "2           3                 0                              0.658180   38   \n",
       "3           4                 0                              0.233810   30   \n",
       "4           5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                     2   0.802982         9120.0   \n",
       "1                                     0   0.121876         2600.0   \n",
       "2                                     1   0.085113         3042.0   \n",
       "3                                     0   0.036050         3300.0   \n",
       "4                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                               13                        0   \n",
       "1                                4                        0   \n",
       "2                                2                        1   \n",
       "3                                5                        0   \n",
       "4                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                             6                                     0   \n",
       "1                             0                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 2.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column in the training data has an ambuigous name, therefore, I renamed it to be 'Observation ID'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns={'Unnamed: 0': 'ObversationId'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   ObversationId                         150000 non-null  int64  \n",
      " 1   SeriousDlqin2yrs                      150000 non-null  int64  \n",
      " 2   RevolvingUtilizationOfUnsecuredLines  150000 non-null  float64\n",
      " 3   age                                   150000 non-null  int64  \n",
      " 4   NumberOfTime30-59DaysPastDueNotWorse  150000 non-null  int64  \n",
      " 5   DebtRatio                             150000 non-null  float64\n",
      " 6   MonthlyIncome                         120269 non-null  float64\n",
      " 7   NumberOfOpenCreditLinesAndLoans       150000 non-null  int64  \n",
      " 8   NumberOfTimes90DaysLate               150000 non-null  int64  \n",
      " 9   NumberRealEstateLoansOrLines          150000 non-null  int64  \n",
      " 10  NumberOfTime60-89DaysPastDueNotWorse  150000 non-null  int64  \n",
      " 11  NumberOfDependents                    146076 non-null  float64\n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 13.7 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary informs me about the missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Missing Data</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ObversationId</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Number of Missing Data  Ratio\n",
       "ObversationId                                              0   0.00\n",
       "SeriousDlqin2yrs                                           0   0.00\n",
       "RevolvingUtilizationOfUnsecuredLines                       0   0.00\n",
       "age                                                        0   0.00\n",
       "NumberOfTime30-59DaysPastDueNotWorse                       0   0.00\n",
       "DebtRatio                                                  0   0.00\n",
       "MonthlyIncome                                          29731  19.82\n",
       "NumberOfOpenCreditLinesAndLoans                            0   0.00\n",
       "NumberOfTimes90DaysLate                                    0   0.00\n",
       "NumberRealEstateLoansOrLines                               0   0.00\n",
       "NumberOfTime60-89DaysPastDueNotWorse                       0   0.00\n",
       "NumberOfDependents                                      3924   2.62"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Number of Missing Data\":train.isnull().sum(),\n",
    "             \"Ratio\":round(train.isnull().sum()/len(train)*100,2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObversationId</th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.202690e+05</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>146076.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75000.500000</td>\n",
       "      <td>0.066840</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>6.670221e+03</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>0.757222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43301.414527</td>\n",
       "      <td>0.249746</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>1.438467e+04</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>1.115086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37500.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>3.400000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>5.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112500.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>8.249000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>3.008750e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ObversationId  SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  \\\n",
       "count  150000.000000     150000.000000                         150000.000000   \n",
       "mean    75000.500000          0.066840                              6.048438   \n",
       "std     43301.414527          0.249746                            249.755371   \n",
       "min         1.000000          0.000000                              0.000000   \n",
       "25%     37500.750000          0.000000                              0.029867   \n",
       "50%     75000.500000          0.000000                              0.154181   \n",
       "75%    112500.250000          0.000000                              0.559046   \n",
       "max    150000.000000          1.000000                          50708.000000   \n",
       "\n",
       "                 age  NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  \\\n",
       "count  150000.000000                         150000.000000  150000.000000   \n",
       "mean       52.295207                              0.421033     353.005076   \n",
       "std        14.771866                              4.192781    2037.818523   \n",
       "min         0.000000                              0.000000       0.000000   \n",
       "25%        41.000000                              0.000000       0.175074   \n",
       "50%        52.000000                              0.000000       0.366508   \n",
       "75%        63.000000                              0.000000       0.868254   \n",
       "max       109.000000                             98.000000  329664.000000   \n",
       "\n",
       "       MonthlyIncome  NumberOfOpenCreditLinesAndLoans  \\\n",
       "count   1.202690e+05                    150000.000000   \n",
       "mean    6.670221e+03                         8.452760   \n",
       "std     1.438467e+04                         5.145951   \n",
       "min     0.000000e+00                         0.000000   \n",
       "25%     3.400000e+03                         5.000000   \n",
       "50%     5.400000e+03                         8.000000   \n",
       "75%     8.249000e+03                        11.000000   \n",
       "max     3.008750e+06                        58.000000   \n",
       "\n",
       "       NumberOfTimes90DaysLate  NumberRealEstateLoansOrLines  \\\n",
       "count            150000.000000                 150000.000000   \n",
       "mean                  0.265973                      1.018240   \n",
       "std                   4.169304                      1.129771   \n",
       "min                   0.000000                      0.000000   \n",
       "25%                   0.000000                      0.000000   \n",
       "50%                   0.000000                      1.000000   \n",
       "75%                   0.000000                      2.000000   \n",
       "max                  98.000000                     54.000000   \n",
       "\n",
       "       NumberOfTime60-89DaysPastDueNotWorse  NumberOfDependents  \n",
       "count                         150000.000000       146076.000000  \n",
       "mean                               0.240387            0.757222  \n",
       "std                                4.155179            1.115086  \n",
       "min                                0.000000            0.000000  \n",
       "25%                                0.000000            0.000000  \n",
       "50%                                0.000000            0.000000  \n",
       "75%                                0.000000            1.000000  \n",
       "max                               98.000000           20.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, we can find out that many values could be a mistake, for example, the minimum age is 0, the maximum debtratio is 329664, and the maximum NumberOfTimes90DaysLate/NumberOfTime60-89DaysPastDueNotWorse are 98. These outliers need to be removed.\n",
    "\n",
    "I explore each feature by visualization and/or a summary statistics. For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='NumberOfTime30-59DaysPastDueNotWorse', ylabel='count'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data = train, x = \"NumberOfTime30-59DaysPastDueNotWorse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='NumberOfTimes90DaysLate', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data = train, x = \"NumberOfTimes90DaysLate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the above 2 figures, a majority of users will not pass due without noticing the bank in the past 2 years. There are some obvious outliers, i.e. the 96 and 98 times from both figures. This clearly doesn't make sense as user can't pass due 96 times within 2 years. Therefore, in the following data cleaning part, we also need to deal with outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fb112e94fa0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 638.222x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(train, x = \"age\", kde=True, hue= \"SeriousDlqin2yrs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above user age distribution by category, it seems that younger users have a higher tendency to experience 90 days past due delinquency or worse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have an intuitive understanding of our dataset, I plotted the following visualizations,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='age'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=train, x=\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='DebtRatio'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=train, x=\"DebtRatio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above boxplots, I can identify some outliers within our 150,000 observations. For simplicity, I decided to remove the outliers with Turkey's procedure which could affect the following data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations dropped:  3527\n"
     ]
    }
   ],
   "source": [
    "indices = []\n",
    "    \n",
    "for col in train.columns.values[2:]: \n",
    "    \n",
    "    # calculate IQR\n",
    "    Q1 = np.percentile(train[col], 25)\n",
    "    Q3 = np.percentile(train[col],75)\n",
    "    IQR = Q3 - Q1\n",
    "    step = 1.5 * IQR\n",
    "    \n",
    "    # find the index that contains outliers\n",
    "    list_col = train[(train[col] < Q1 - step) | (train[col] > Q3 + step )].index\n",
    "    indices.extend(list_col)\n",
    "    \n",
    "# remove the observations when they have 2 or more features that are outliers\n",
    "indices = Counter(indices) \n",
    "outliers = list(k for k, v in indices.items() if v > 2)\n",
    "print(\"Number of observations dropped: \", len(outliers))\n",
    "train = train.drop(train.index[outliers]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146473 entries, 0 to 146472\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   ObversationId                         146473 non-null  int64  \n",
      " 1   SeriousDlqin2yrs                      146473 non-null  int64  \n",
      " 2   RevolvingUtilizationOfUnsecuredLines  146473 non-null  float64\n",
      " 3   age                                   146473 non-null  int64  \n",
      " 4   NumberOfTime30-59DaysPastDueNotWorse  146473 non-null  int64  \n",
      " 5   DebtRatio                             146473 non-null  float64\n",
      " 6   MonthlyIncome                         118224 non-null  float64\n",
      " 7   NumberOfOpenCreditLinesAndLoans       146473 non-null  int64  \n",
      " 8   NumberOfTimes90DaysLate               146473 non-null  int64  \n",
      " 9   NumberRealEstateLoansOrLines          146473 non-null  int64  \n",
      " 10  NumberOfTime60-89DaysPastDueNotWorse  146473 non-null  int64  \n",
      " 11  NumberOfDependents                    142707 non-null  float64\n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 13.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `info` table, I can find out that the training data has 10 predictors as well as 1 response variables (`SeriousDlqin2yrs`). Most of the features have 146,473 observations after I have dropped the outliers, however, `MonthlyIncome` and `NumberOfDependents` have a noticable amount of missing values. Therefore, I need to properly deal with the missing values for these two columns before progressing to the next step of data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `NumberOfDependents` only have a few (2.6%) missing records and there is no clear pattern between this feature and other selected features, or our response variable, I choose to assign `NumberOfDependents` based on its nearest 5 neighbors. For simplicity, I also used KNN with N = 5 to decide what the missing value should be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NumberOfDependents'].fillna(0,inplace=True)\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "train_imputed = imputer.fit_transform(train)\n",
    "train = pd.DataFrame(train_imputed, columns=train.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146473 entries, 0 to 146472\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   ObversationId                         146473 non-null  float64\n",
      " 1   SeriousDlqin2yrs                      146473 non-null  float64\n",
      " 2   RevolvingUtilizationOfUnsecuredLines  146473 non-null  float64\n",
      " 3   age                                   146473 non-null  float64\n",
      " 4   NumberOfTime30-59DaysPastDueNotWorse  146473 non-null  float64\n",
      " 5   DebtRatio                             146473 non-null  float64\n",
      " 6   MonthlyIncome                         146473 non-null  float64\n",
      " 7   NumberOfOpenCreditLinesAndLoans       146473 non-null  float64\n",
      " 8   NumberOfTimes90DaysLate               146473 non-null  float64\n",
      " 9   NumberRealEstateLoansOrLines          146473 non-null  float64\n",
      " 10  NumberOfTime60-89DaysPastDueNotWorse  146473 non-null  float64\n",
      " 11  NumberOfDependents                    146473 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 13.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the missing data has been properly computed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Imbalance for the response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '138176'), Text(0, 0, '8297')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=train[\"SeriousDlqin2yrs\"])\n",
    "ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figure, I discover that there is salient imbalance for the response variable, as a result, we have to apply some resample techniques before analyzing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['SeriousDlqin2yrs']\n",
    "X = train.drop(['ObversationId', 'SeriousDlqin2yrs'], axis = 1)\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Yes:  138176\n",
      "Number of No:  138176\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Yes: \", sum(y_resampled == 1))\n",
    "print(\"Number of No: \", sum(y_resampled == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step of data preprocessing is to to rescale the features through standardization so that they can have a mean as 0 and variance as 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_resampled)\n",
    "X_resampled = scaler.transform(X_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I fit a logistic regression. Instead of using traditional training and testing split, I choose to use the default `LogisticRegressionCV` function and specifies the `scoring` to be `roc_auc`. AUC is the area under the ROC (Receiver Operating Characteristics) curve. ROC curve has False Positive Rate as its x-axis and True Positive Rate as its y-axis. If the AUC is closer to 1, it means that our model can greatly identify the two classes. On the other hand, if the AUC is closer to 0.5, it means that our model has a poor performance as random guessing would have an auc of 0.5.\n",
    "- I choose to use the average auc (area under the roc curve) value from 8-fold cross validation as the evaluation criteria. \n",
    "- I choose the metric to be auc value over F-1 score, accuracy, precision/recall because it’s the evaluation metric for this challenge. It’s better to keep consistent with the evaluation metric of the stakeholders. \n",
    "- I choose to use k-fold cross validation instead of a simple train test split so that my result can be more robust. If only one random seed is chosen and one set of auc score is calculated from one train-test split, the auc score can happen by chance.\n",
    "- Other metrics that can be suitable for this competition is recall, which is the number of true positive over the sum of true positive and false negative. This is important because for the banks, they want to increase their recall so as to avoid missing the customers who is gonna to experience 90 days past due delinquency or worse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we don't consider the interaction effect between the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8406138138272438"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv=8, random_state=42, scoring='roc_auc').fit(X_resampled, y_resampled)\n",
    "clf.score(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the average auc score for my logistic regression model is 0.84, which is desirable. Then, I investigate on which individual factors have a higher influence on our response by first calculating the logit odd of our coefficients as follows, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97582292, 0.63083318, 2.4110578 , 0.90508833, 0.79765914,\n",
       "        1.06207591, 3.93145483, 1.14172231, 1.98578707, 1.06432825]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: \n",
    "- As the logit odd of the age is 0.63, this means younger people are more likely to experience 90 days past due delinquency or worse. \n",
    "- As the logit odd of the number of times borrower has been 30-59 days past due has a logit odd of 2.411, it indicates that users who have past due for no more than 59 days more frequently are more likely to experience 90 days past due delinquency or worse. \n",
    "- Similarly, the number of times borrower has been 90 days or more past due. This indicates that users who have past due over 90 days more frequently are more likely to experience 90 days past due delinquency or worse.\n",
    "- A similar result can be drawn for the number of times borrower has been 60-89 days past due.\n",
    "- Other factors don't affect the probability of experiencing 90 days past due delinquency or worse as much as the above four factors as other factors have a logit odd value more close to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I would like to conduct a ploynomial logistic regression up to degree 2 to test the interaction effects among the variables. I used `PolynomialFeatures` package, set the `degree` to be 2 and the `interaction_only` parameter to be True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 2, interaction_only = True)\n",
    "X_poly = poly.fit_transform(X_resampled)\n",
    "\n",
    "lr = LogisticRegressionCV(cv=8, random_state=42, scoring='roc_auc', solver = 'sag', max_iter=500).fit(X_poly, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8430093975763617"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_poly, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66154631, 2.3224084 , 4.34250193, 1.97210232, 0.67471521])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = np.exp(lr.coef_)\n",
    "choice = np.logical_or(np.greater(coefs, 1.3), np.less(coefs, 0.7))\n",
    "np.extract(choice, coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.093658  , 1.00459668, 0.66154631, 2.3224084 , 0.84137566,\n",
       "        0.76693069, 1.06630682, 4.34250193, 1.15928579, 1.97210232,\n",
       "        1.05070493, 1.0057228 , 0.97531208, 0.92135257, 0.91094172,\n",
       "        1.04562219, 1.0804524 , 1.01362894, 1.03080965, 0.98600402,\n",
       "        1.06954276, 0.83961536, 0.86416374, 0.9954921 , 1.1062228 ,\n",
       "        0.99596643, 1.1103626 , 1.00819084, 1.05849785, 1.02097389,\n",
       "        0.86452381, 0.67471521, 0.97837699, 0.78198206, 0.96960519,\n",
       "        1.17694664, 1.09881472, 0.90070742, 1.03877715, 0.96869169,\n",
       "        0.95615096, 1.07608583, 1.12035032, 1.05284838, 0.94588151,\n",
       "        0.97907425, 1.17558302, 1.05200773, 0.95777624, 0.97684268,\n",
       "        1.18940968, 0.78007533, 0.93106354, 1.0327901 , 0.97009891,\n",
       "        0.99351564]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we can say there are some interaction effects between some of the predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885519</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177513</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.463295</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527237</td>\n",
       "      <td>9141.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043275</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687648</td>\n",
       "      <td>5083.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280308</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925961</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>3865.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "0           1               NaN                              0.885519   43   \n",
       "1           2               NaN                              0.463295   57   \n",
       "2           3               NaN                              0.043275   59   \n",
       "3           4               NaN                              0.280308   38   \n",
       "4           5               NaN                              1.000000   27   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                     0   0.177513         5700.0   \n",
       "1                                     0   0.527237         9141.0   \n",
       "2                                     0   0.687648         5083.0   \n",
       "3                                     1   0.925961         3200.0   \n",
       "4                                     0   0.019917         3865.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                                4                        0   \n",
       "1                               15                        0   \n",
       "2                               12                        0   \n",
       "3                                7                        0   \n",
       "4                                4                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                             0                                     0   \n",
       "1                             4                                     0   \n",
       "2                             1                                     0   \n",
       "3                             2                                     0   \n",
       "4                             0                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 0.0  \n",
       "1                 2.0  \n",
       "2                 2.0  \n",
       "3                 0.0  \n",
       "4                 1.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/cs-test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.rename(columns={'Unnamed: 0': 'ObversationId'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101503 entries, 0 to 101502\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   ObversationId                         101503 non-null  int64  \n",
      " 1   SeriousDlqin2yrs                      0 non-null       float64\n",
      " 2   RevolvingUtilizationOfUnsecuredLines  101503 non-null  float64\n",
      " 3   age                                   101503 non-null  int64  \n",
      " 4   NumberOfTime30-59DaysPastDueNotWorse  101503 non-null  int64  \n",
      " 5   DebtRatio                             101503 non-null  float64\n",
      " 6   MonthlyIncome                         81400 non-null   float64\n",
      " 7   NumberOfOpenCreditLinesAndLoans       101503 non-null  int64  \n",
      " 8   NumberOfTimes90DaysLate               101503 non-null  int64  \n",
      " 9   NumberRealEstateLoansOrLines          101503 non-null  int64  \n",
      " 10  NumberOfTime60-89DaysPastDueNotWorse  101503 non-null  int64  \n",
      " 11  NumberOfDependents                    98877 non-null   float64\n",
      "dtypes: float64(5), int64(7)\n",
      "memory usage: 9.3 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['ObversationId', 'SeriousDlqin2yrs'], axis = 1)\n",
    "test['NumberOfDependents'].fillna(0,inplace=True)\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "test_imputed = imputer.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_imputed, columns=test.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.885519</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177513</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.463295</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527237</td>\n",
       "      <td>9141.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043275</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687648</td>\n",
       "      <td>5083.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.280308</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925961</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>3865.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RevolvingUtilizationOfUnsecuredLines   age  \\\n",
       "0                              0.885519  43.0   \n",
       "1                              0.463295  57.0   \n",
       "2                              0.043275  59.0   \n",
       "3                              0.280308  38.0   \n",
       "4                              1.000000  27.0   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                   0.0   0.177513         5700.0   \n",
       "1                                   0.0   0.527237         9141.0   \n",
       "2                                   0.0   0.687648         5083.0   \n",
       "3                                   1.0   0.925961         3200.0   \n",
       "4                                   0.0   0.019917         3865.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                              4.0                      0.0   \n",
       "1                             15.0                      0.0   \n",
       "2                             12.0                      0.0   \n",
       "3                              7.0                      0.0   \n",
       "4                              4.0                      0.0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                           0.0                                   0.0   \n",
       "1                           4.0                                   0.0   \n",
       "2                           1.0                                   0.0   \n",
       "3                           2.0                                   0.0   \n",
       "4                           0.0                                   0.0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 0.0  \n",
       "1                 2.0  \n",
       "2                 2.0  \n",
       "3                 0.0  \n",
       "4                 1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(test)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = clf.predict_proba(test)[:,1]\n",
    "\n",
    "result = pd.read_csv('data/sampleEntry.csv') \n",
    "result['Probability'] = y_test_predicted\n",
    "result.to_csv('data/submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above estimated probability for logistic regression without considering interaction effect has a private score of 0.766 on Kaggle. Consider that this is the result of logistic regression, it is acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 2, interaction_only = True)\n",
    "X_poly_test = poly.fit_transform(test)\n",
    "y_test_predicted = lr.predict_proba(X_poly_test)[:,1]\n",
    "\n",
    "result = pd.read_csv('data/sampleEntry.csv') \n",
    "result['Probability'] = y_test_predicted\n",
    "result.to_csv('data/submit2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probability for logistic regression witn interaction effect has a private score of 0.753 on Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I tried to use tree-based method. Specifially, I used random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6],\n",
       "                         &#x27;n_estimators&#x27;: [25, 50, 100, 200]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [4, 6, 8, 10],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6],\n",
       "                         &#x27;n_estimators&#x27;: [25, 50, 100, 200]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'min_samples_leaf': [1, 2, 4, 6],\n",
       "                         'n_estimators': [25, 50, 100, 200]},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state= 42) \n",
    "\n",
    "search_grid = {\n",
    "        'max_depth': [4, 6, 8, 10],\n",
    "        'min_samples_leaf': [1, 2, 4, 6],\n",
    "        'n_estimators': [25, 50, 100, 200], \n",
    "        'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(estimator = clf, param_grid = search_grid, cv = 5, verbose=1, scoring='roc_auc')\n",
    "grid_clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid_clf.best_estimator_\n",
    "grid_clf.best_params_\n",
    "# grid_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state= 42, max_depth = 10, min_samples_leaf = 1, n_estimators = 100, criterion = 'gini')\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_test_predicted = clf.predict_proba(test)[:,1]\n",
    "\n",
    "result = pd.read_csv('data/sampleEntry.csv') \n",
    "result['Probability'] = y_test_predicted\n",
    "result.to_csv('data/submit3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The private score for this random forest model is 0.856, which is better than logistic regression, and is closer to the TOP 100 scores (highest: 0.869) on Kaggle.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light GBM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I would like to try on the performance of light gradient boosting machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(n_estimators=150,colsample_bytree=0.95,subsample=0.95, learning_rate=0.015, metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.95, learning_rate=0.015, n_estimators=150,\n",
       "               subsample=0.95)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.95, learning_rate=0.015, n_estimators=150,\n",
       "               subsample=0.95)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.95, learning_rate=0.015, n_estimators=150,\n",
       "               subsample=0.95)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = clf.predict_proba(test)[:,1]\n",
    "\n",
    "result = pd.read_csv('data/sampleEntry.csv') \n",
    "result['Probability'] = y_test_predicted\n",
    "result.to_csv('data/submit5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "[CV 5/5; 1/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 1/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.919 total time=   4.6s\n",
      "[CV 1/5; 2/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 2/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.842 total time=  13.8s\n",
      "[CV 5/5; 3/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 3/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.985 total time=  22.9s\n",
      "[CV 4/5; 4/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 4/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.920 total time=   5.0s\n",
      "[CV 5/5; 5/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 5/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.976 total time=  17.0s\n",
      "[CV 3/5; 6/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 6/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.986 total time=  25.6s\n",
      "[CV 2/5; 7/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 7/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.922 total time=   5.2s\n",
      "[CV 2/5; 8/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 8/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.974 total time=  13.5s\n",
      "[CV 4/5; 9/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 9/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.986 total time=  23.9s\n",
      "[CV 4/5; 10/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 10/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.950 total time=   6.9s\n",
      "[CV 4/5; 11/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 11/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.986 total time=  15.6s\n",
      "[CV 4/5; 12/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 12/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  23.9s\n",
      "[CV 3/5; 13/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 13/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.950 total time=   6.0s\n",
      "[CV 3/5; 14/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 14/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.985 total time=  15.4s\n",
      "[CV 3/5; 15/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 15/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  26.5s\n",
      "[CV 3/5; 16/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 16/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.950 total time=   7.4s\n",
      "[CV 3/5; 17/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 17/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.985 total time=  16.5s\n",
      "[CV 2/5; 18/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 18/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  23.8s\n",
      "[CV 2/5; 19/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 19/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.950 total time=   5.1s\n",
      "[CV 2/5; 20/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 20/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.987 total time=  14.8s\n",
      "[CV 2/5; 21/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 21/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  23.7s\n",
      "[CV 2/5; 22/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 22/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.950 total time=   5.5s\n",
      "[CV 2/5; 23/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 23/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.987 total time=  14.4s\n",
      "[CV 2/5; 24/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 24/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  21.9s\n",
      "[CV 1/5; 25/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 25/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.839 total time=   5.1s\n",
      "[CV 1/5; 26/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 26/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.845 total time=  14.6s\n",
      "[CV 1/5; 27/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 27/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.847 total time=  24.3s\n",
      "[CV 2/5; 28/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 28/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.897 total time=   4.5s\n",
      "[CV 2/5; 29/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 29/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.962 total time=  12.7s\n",
      "[CV 2/5; 30/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 30/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.975 total time=  19.9s\n",
      "[CV 1/5; 31/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 31/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.817 total time=   4.6s\n",
      "[CV 5/5; 31/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 31/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.899 total time=   4.5s\n",
      "[CV 5/5; 32/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[CV 3/5; 1/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 1/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.919 total time=   4.5s\n",
      "[CV 3/5; 2/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 2/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.976 total time=  13.2s\n",
      "[CV 1/5; 3/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 3/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.842 total time=  23.7s\n",
      "[CV 5/5; 4/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 4/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.919 total time=   4.7s\n",
      "[CV 3/5; 5/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 5/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.976 total time=  18.3s\n",
      "[CV 5/5; 6/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 6/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  25.0s\n",
      "[CV 4/5; 7/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 7/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.920 total time=   5.2s\n",
      "[CV 4/5; 8/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 8/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.976 total time=  12.5s\n",
      "[CV 3/5; 9/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 9/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.985 total time=  22.2s\n",
      "[CV 2/5; 10/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 10/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.950 total time=   6.7s\n",
      "[CV 2/5; 11/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 11/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.984 total time=  16.4s\n",
      "[CV 2/5; 12/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 12/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.989 total time=  23.6s\n",
      "[CV 1/5; 13/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 13/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.839 total time=   6.1s\n",
      "[CV 1/5; 14/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 14/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.844 total time=  16.3s\n",
      "[CV 1/5; 15/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 15/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.847 total time=  26.9s\n",
      "[CV 1/5; 16/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 16/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.839 total time=   7.3s\n",
      "[CV 1/5; 17/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 17/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.844 total time=  16.2s\n",
      "[CV 1/5; 18/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 18/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.847 total time=  24.4s\n",
      "[CV 1/5; 19/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 19/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.839 total time=   5.0s\n",
      "[CV 5/5; 19/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 19/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.953 total time=   5.1s\n",
      "[CV 5/5; 20/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 20/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.988 total time=  15.1s\n",
      "[CV 5/5; 21/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 21/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  21.8s\n",
      "[CV 5/5; 22/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 22/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.953 total time=   5.5s\n",
      "[CV 5/5; 23/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 23/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.988 total time=  15.7s\n",
      "[CV 5/5; 24/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 24/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  21.9s\n",
      "[CV 5/5; 25/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 25/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.953 total time=   5.1s\n",
      "[CV 5/5; 26/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 26/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.988 total time=  14.6s\n",
      "[CV 5/5; 27/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 27/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  23.3s\n",
      "[CV 5/5; 28/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 28/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.899 total time=   4.5s\n",
      "[CV 5/5; 29/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 29/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.963 total time=  12.6s\n",
      "[CV 5/5; 30/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 30/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.976 total time=  21.1s\n",
      "[CV 1/5; 32/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 32/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.843 total time=  12.3s\n",
      "[CV 1/5; 33/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[CV 2/5; 1/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 1/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.922 total time=   4.9s\n",
      "[CV 5/5; 2/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 2/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.976 total time=  13.2s\n",
      "[CV 4/5; 3/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 3/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.985 total time=  23.0s\n",
      "[CV 3/5; 4/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 4/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.919 total time=   5.2s\n",
      "[CV 4/5; 5/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 5/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.976 total time=  16.8s\n",
      "[CV 1/5; 6/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 6/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.843 total time=  26.2s\n",
      "[CV 3/5; 7/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 7/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.919 total time=   5.2s\n",
      "[CV 3/5; 8/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 8/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.976 total time=  12.5s\n",
      "[CV 2/5; 9/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 9/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.985 total time=  22.3s\n",
      "[CV 3/5; 10/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 10/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.950 total time=   6.8s\n",
      "[CV 3/5; 11/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 11/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.986 total time=  17.6s\n",
      "[CV 3/5; 12/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 12/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.991 total time=  25.8s\n",
      "[CV 4/5; 13/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 13/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.950 total time=   5.6s\n",
      "[CV 4/5; 14/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 14/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.986 total time=  15.2s\n",
      "[CV 4/5; 15/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 15/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  26.9s\n",
      "[CV 4/5; 16/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 16/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.950 total time=   7.0s\n",
      "[CV 4/5; 17/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 17/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.986 total time=  16.4s\n",
      "[CV 4/5; 18/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 18/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  23.7s\n",
      "[CV 3/5; 19/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 19/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.952 total time=   5.0s\n",
      "[CV 3/5; 20/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 20/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.988 total time=  14.8s\n",
      "[CV 3/5; 21/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 21/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.991 total time=  21.9s\n",
      "[CV 1/5; 22/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 22/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.839 total time=   5.5s\n",
      "[CV 1/5; 23/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 23/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.845 total time=  14.5s\n",
      "[CV 1/5; 24/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 24/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.847 total time=  24.4s\n",
      "[CV 3/5; 25/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 25/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.952 total time=   5.1s\n",
      "[CV 3/5; 26/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 26/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.988 total time=  14.5s\n",
      "[CV 3/5; 27/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 27/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  23.5s\n",
      "[CV 3/5; 28/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 28/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.898 total time=   4.5s\n",
      "[CV 3/5; 29/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 29/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.963 total time=  12.5s\n",
      "[CV 3/5; 30/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 30/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.975 total time=  21.4s\n",
      "[CV 4/5; 31/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 31/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.897 total time=   4.6s\n",
      "[CV 4/5; 32/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 32/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.964 total time=  12.8s\n",
      "[CV 4/5; 33/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[CV 4/5; 1/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 1/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.920 total time=   4.6s\n",
      "[CV 2/5; 2/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 2/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.974 total time=  13.3s\n",
      "[CV 3/5; 3/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 3/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.986 total time=  23.1s\n",
      "[CV 2/5; 4/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 4/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.922 total time=   4.6s\n",
      "[CV 1/5; 5/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 5/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.841 total time=  17.7s\n",
      "[CV 2/5; 6/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 6/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  25.4s\n",
      "[CV 1/5; 7/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 7/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.827 total time=   5.2s\n",
      "[CV 1/5; 8/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 8/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.842 total time=  12.2s\n",
      "[CV 1/5; 9/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 9/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.843 total time=  23.0s\n",
      "[CV 1/5; 10/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 10/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.839 total time=   6.9s\n",
      "[CV 1/5; 11/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 11/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.843 total time=  16.2s\n",
      "[CV 1/5; 12/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 12/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.846 total time=  24.1s\n",
      "[CV 2/5; 13/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 13/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.950 total time=   5.5s\n",
      "[CV 2/5; 14/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 14/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.985 total time=  16.7s\n",
      "[CV 2/5; 15/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 15/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  26.4s\n",
      "[CV 2/5; 16/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 16/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.950 total time=   7.3s\n",
      "[CV 2/5; 17/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 17/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.985 total time=  17.9s\n",
      "[CV 3/5; 18/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 18/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.991 total time=  23.8s\n",
      "[CV 4/5; 19/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 19/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.951 total time=   5.0s\n",
      "[CV 4/5; 20/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 20/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.988 total time=  14.8s\n",
      "[CV 4/5; 21/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 21/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  23.6s\n",
      "[CV 4/5; 22/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 22/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.951 total time=   5.2s\n",
      "[CV 4/5; 23/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 23/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.988 total time=  14.4s\n",
      "[CV 4/5; 24/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 24/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  23.6s\n",
      "[CV 4/5; 25/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 25/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.951 total time=   5.6s\n",
      "[CV 4/5; 26/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 26/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.988 total time=  14.5s\n",
      "[CV 4/5; 27/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 27/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  23.5s\n",
      "[CV 4/5; 28/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 28/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.897 total time=   4.5s\n",
      "[CV 4/5; 29/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 29/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.964 total time=  12.7s\n",
      "[CV 4/5; 30/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 30/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.976 total time=  19.8s\n",
      "[CV 3/5; 31/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 31/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.898 total time=   4.9s\n",
      "[CV 3/5; 32/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 32/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.963 total time=  12.8s\n",
      "[CV 3/5; 33/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[CV 1/5; 1/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 1/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.827 total time=   4.6s\n",
      "[CV 4/5; 2/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 2/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.976 total time=  13.2s\n",
      "[CV 2/5; 3/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 3/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.985 total time=  23.0s\n",
      "[CV 1/5; 4/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 4/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.827 total time=   5.0s\n",
      "[CV 2/5; 5/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 5/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.975 total time=  18.0s\n",
      "[CV 4/5; 6/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 6/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.986 total time=  26.5s\n",
      "[CV 5/5; 7/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 7/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.919 total time=   5.0s\n",
      "[CV 5/5; 8/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 8/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.976 total time=  12.5s\n",
      "[CV 5/5; 9/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 9/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.985 total time=  24.0s\n",
      "[CV 5/5; 10/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 10/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.951 total time=   7.0s\n",
      "[CV 5/5; 11/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 11/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.986 total time=  15.5s\n",
      "[CV 5/5; 12/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 12/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  25.9s\n",
      "[CV 5/5; 13/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 13/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.951 total time=   5.7s\n",
      "[CV 5/5; 14/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 14/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.986 total time=  15.4s\n",
      "[CV 5/5; 15/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 15/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  29.3s\n",
      "[CV 5/5; 16/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 16/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.951 total time=   7.1s\n",
      "[CV 5/5; 17/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 17/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.985 total time=  17.6s\n",
      "[CV 5/5; 18/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 18/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  23.1s\n",
      "[CV 1/5; 20/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 20/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.845 total time=  14.9s\n",
      "[CV 1/5; 21/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 21/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.847 total time=  24.7s\n",
      "[CV 3/5; 22/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 22/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.952 total time=   5.1s\n",
      "[CV 3/5; 23/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 23/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.988 total time=  14.4s\n",
      "[CV 3/5; 24/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 24/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.991 total time=  22.1s\n",
      "[CV 2/5; 25/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 25/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.950 total time=   5.1s\n",
      "[CV 2/5; 26/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 26/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.987 total time=  14.5s\n",
      "[CV 2/5; 27/162] START bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 27/162] END bagging_fraction=0.6, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.989 total time=  23.3s\n",
      "[CV 1/5; 28/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 28/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.817 total time=   4.5s\n",
      "[CV 1/5; 29/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 29/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.843 total time=  12.4s\n",
      "[CV 1/5; 30/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 30/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.842 total time=  20.9s\n",
      "[CV 2/5; 31/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 31/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.897 total time=   4.6s\n",
      "[CV 2/5; 32/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 32/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.962 total time=  12.5s\n",
      "[CV 2/5; 33/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 33/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.974 total time=  19.8s\n",
      "[CV 2/5; 34/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 33/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.842 total time=  19.1s\n",
      "[CV 1/5; 34/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 34/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.817 total time=   4.5s\n",
      "[CV 5/5; 34/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 34/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.899 total time=   4.4s\n",
      "[CV 5/5; 35/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 35/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.963 total time=  11.8s\n",
      "[CV 5/5; 36/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 36/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.976 total time=  19.1s\n",
      "[CV 5/5; 37/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 37/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.940 total time=   4.9s\n",
      "[CV 5/5; 38/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 38/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.973 total time=  13.4s\n",
      "[CV 5/5; 39/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 39/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.986 total time=  22.1s\n",
      "[CV 1/5; 41/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 41/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.842 total time=  13.4s\n",
      "[CV 1/5; 42/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 42/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.843 total time=  21.2s\n",
      "[CV 1/5; 43/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 43/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.830 total time=   5.0s\n",
      "[CV 4/5; 43/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 43/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.935 total time=   4.9s\n",
      "[CV 4/5; 44/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 44/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.973 total time=  13.4s\n",
      "[CV 4/5; 45/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 45/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.986 total time=  24.1s\n",
      "[CV 5/5; 46/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 46/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.940 total time=   4.8s\n",
      "[CV 5/5; 47/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 47/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.974 total time=  13.5s\n",
      "[CV 5/5; 48/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 48/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.987 total time=  22.6s\n",
      "[CV 5/5; 49/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 49/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.940 total time=   4.9s\n",
      "[CV 5/5; 50/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 50/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.974 total time=  13.7s\n",
      "[CV 4/5; 51/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 51/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.988 total time=  22.5s\n",
      "[CV 4/5; 52/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 52/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.935 total time=   4.9s\n",
      "[CV 4/5; 53/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 53/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.975 total time=  13.6s\n",
      "[CV 4/5; 54/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 54/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.988 total time=  22.8s\n",
      "[CV 4/5; 55/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 55/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.880 total time=   4.3s\n",
      "[CV 4/5; 56/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 56/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.897 total time=  12.6s\n",
      "[CV 4/5; 57/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 57/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.918 total time=  20.7s\n",
      "[CV 4/5; 58/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 58/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.880 total time=   4.3s\n",
      "[CV 4/5; 59/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 59/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.897 total time=  12.4s\n",
      "[CV 4/5; 60/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 60/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.918 total time=  20.2s\n",
      "[CV 3/5; 61/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 61/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.882 total time=   4.3s\n",
      "[CV 3/5; 62/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 62/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.899 total time=  12.2s\n",
      "[CV 3/5; 63/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 63/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.919 total time=  20.2s\n",
      "[CV 4/5; 64/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 64/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.920 total time=   4.8s\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 32/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.963 total time=  12.7s\n",
      "[CV 5/5; 33/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 33/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.976 total time=  19.1s\n",
      "[CV 1/5; 35/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 35/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.843 total time=  11.9s\n",
      "[CV 1/5; 36/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 36/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.842 total time=  18.7s\n",
      "[CV 1/5; 37/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 37/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.830 total time=   4.8s\n",
      "[CV 1/5; 38/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 38/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.842 total time=  13.2s\n",
      "[CV 1/5; 39/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 39/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.843 total time=  21.4s\n",
      "[CV 1/5; 40/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 40/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.830 total time=   4.9s\n",
      "[CV 5/5; 40/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 40/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.940 total time=   4.8s\n",
      "[CV 5/5; 41/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 41/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.973 total time=  13.5s\n",
      "[CV 5/5; 42/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 42/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  22.1s\n",
      "[CV 1/5; 44/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 44/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.842 total time=  13.2s\n",
      "[CV 1/5; 45/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 45/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.843 total time=  21.9s\n",
      "[CV 1/5; 46/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 46/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.830 total time=   5.2s\n",
      "[CV 4/5; 46/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 46/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.935 total time=   4.8s\n",
      "[CV 4/5; 47/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 47/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.975 total time=  14.8s\n",
      "[CV 4/5; 48/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 48/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.988 total time=  22.6s\n",
      "[CV 4/5; 49/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 49/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.935 total time=   5.2s\n",
      "[CV 4/5; 50/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 50/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.975 total time=  14.9s\n",
      "[CV 5/5; 51/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 51/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.988 total time=  22.5s\n",
      "[CV 1/5; 53/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 53/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.843 total time=  13.5s\n",
      "[CV 1/5; 54/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 54/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.844 total time=  22.8s\n",
      "[CV 1/5; 55/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 55/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.798 total time=   4.3s\n",
      "[CV 5/5; 55/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 55/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.881 total time=   4.3s\n",
      "[CV 5/5; 56/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 56/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.899 total time=  12.6s\n",
      "[CV 5/5; 57/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 57/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.921 total time=  20.7s\n",
      "[CV 1/5; 59/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 59/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.816 total time=  12.2s\n",
      "[CV 1/5; 60/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 60/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.827 total time=  19.8s\n",
      "[CV 1/5; 61/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 61/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.798 total time=   4.5s\n",
      "[CV 4/5; 61/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 61/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.880 total time=   4.3s\n",
      "[CV 4/5; 62/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 62/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.897 total time=  12.2s\n",
      "[CV 4/5; 63/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 63/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.918 total time=  20.1s\n",
      "[CV 3/5; 64/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 64/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.921 total time=   4.8s\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 33/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.976 total time=  19.2s\n",
      "[CV 3/5; 34/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 34/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.898 total time=   4.5s\n",
      "[CV 4/5; 35/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 35/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.964 total time=  11.9s\n",
      "[CV 4/5; 36/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 36/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.976 total time=  19.2s\n",
      "[CV 4/5; 37/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 37/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.935 total time=   4.9s\n",
      "[CV 4/5; 38/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 38/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.973 total time=  13.4s\n",
      "[CV 4/5; 39/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 39/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.986 total time=  22.1s\n",
      "[CV 4/5; 40/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 40/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.935 total time=   4.8s\n",
      "[CV 4/5; 41/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 41/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.973 total time=  13.6s\n",
      "[CV 3/5; 42/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 42/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  22.1s\n",
      "[CV 3/5; 43/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 43/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.938 total time=   4.9s\n",
      "[CV 3/5; 44/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 44/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.973 total time=  13.5s\n",
      "[CV 3/5; 45/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 45/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.986 total time=  22.4s\n",
      "[CV 3/5; 46/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 46/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.939 total time=   5.2s\n",
      "[CV 3/5; 47/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 47/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.975 total time=  13.6s\n",
      "[CV 3/5; 48/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 48/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.988 total time=  22.6s\n",
      "[CV 3/5; 49/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 49/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.939 total time=   4.8s\n",
      "[CV 3/5; 50/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 50/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.975 total time=  13.8s\n",
      "[CV 3/5; 51/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 51/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.988 total time=  22.5s\n",
      "[CV 3/5; 52/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 52/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.939 total time=   4.9s\n",
      "[CV 3/5; 53/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 53/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.975 total time=  13.6s\n",
      "[CV 3/5; 54/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 54/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.988 total time=  22.8s\n",
      "[CV 3/5; 55/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 55/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.882 total time=   4.5s\n",
      "[CV 3/5; 56/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 56/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.899 total time=  13.6s\n",
      "[CV 3/5; 57/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 57/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.919 total time=  20.9s\n",
      "[CV 3/5; 58/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 58/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.882 total time=   4.3s\n",
      "[CV 3/5; 59/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 59/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.899 total time=  12.4s\n",
      "[CV 2/5; 60/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 60/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.920 total time=  21.7s\n",
      "[CV 1/5; 62/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 62/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.816 total time=  11.9s\n",
      "[CV 1/5; 63/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 63/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.827 total time=  19.6s\n",
      "[CV 1/5; 64/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 64/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.820 total time=   4.8s\n",
      "[CV 1/5; 65/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 65/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.830 total time=  13.1s\n",
      "[CV 1/5; 66/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 66/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.839 total time=  21.7s\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 34/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.897 total time=   4.4s\n",
      "[CV 2/5; 35/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 35/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.962 total time=  12.0s\n",
      "[CV 2/5; 36/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 36/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.975 total time=  19.3s\n",
      "[CV 2/5; 37/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 37/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.935 total time=   5.2s\n",
      "[CV 2/5; 38/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 38/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.972 total time=  13.4s\n",
      "[CV 2/5; 39/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 39/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.985 total time=  22.1s\n",
      "[CV 2/5; 40/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 40/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.935 total time=   4.8s\n",
      "[CV 2/5; 41/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 41/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.972 total time=  13.6s\n",
      "[CV 2/5; 42/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 42/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  21.9s\n",
      "[CV 2/5; 43/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 43/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.935 total time=   4.9s\n",
      "[CV 2/5; 44/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 44/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.972 total time=  13.4s\n",
      "[CV 2/5; 45/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 45/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.984 total time=  22.2s\n",
      "[CV 2/5; 46/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 46/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.937 total time=   4.8s\n",
      "[CV 2/5; 47/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 47/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.973 total time=  13.5s\n",
      "[CV 2/5; 48/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 48/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.987 total time=  22.4s\n",
      "[CV 2/5; 49/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 49/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.937 total time=   4.8s\n",
      "[CV 2/5; 50/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 50/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.973 total time=  13.7s\n",
      "[CV 2/5; 51/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 51/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.987 total time=  22.3s\n",
      "[CV 1/5; 52/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 52/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.830 total time=   4.8s\n",
      "[CV 5/5; 52/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 52/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.940 total time=   4.8s\n",
      "[CV 5/5; 53/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 53/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.974 total time=  13.6s\n",
      "[CV 5/5; 54/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 54/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.988 total time=  22.8s\n",
      "[CV 1/5; 56/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 56/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.816 total time=  12.4s\n",
      "[CV 1/5; 57/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 57/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.827 total time=  20.3s\n",
      "[CV 1/5; 58/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 58/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.798 total time=   4.5s\n",
      "[CV 5/5; 58/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 58/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.881 total time=   4.4s\n",
      "[CV 5/5; 59/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 59/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.899 total time=  12.3s\n",
      "[CV 5/5; 60/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 60/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.921 total time=  20.3s\n",
      "[CV 5/5; 61/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 61/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.881 total time=   4.3s\n",
      "[CV 5/5; 62/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 62/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.899 total time=  12.1s\n",
      "[CV 5/5; 63/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 63/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.921 total time=  20.1s\n",
      "[CV 5/5; 64/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 64/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.925 total time=   4.8s\n",
      "[CV 5/5; 65/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 65/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.939 total time=  14.3s\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 33/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.975 total time=  19.4s\n",
      "[CV 4/5; 34/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 34/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.897 total time=   4.4s\n",
      "[CV 3/5; 35/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 35/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.963 total time=  11.9s\n",
      "[CV 3/5; 36/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 36/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.975 total time=  19.3s\n",
      "[CV 3/5; 37/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 37/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.938 total time=   4.8s\n",
      "[CV 3/5; 38/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 38/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.973 total time=  13.3s\n",
      "[CV 3/5; 39/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 39/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.986 total time=  22.2s\n",
      "[CV 3/5; 40/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 40/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.938 total time=   4.8s\n",
      "[CV 3/5; 41/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 41/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.973 total time=  14.8s\n",
      "[CV 4/5; 42/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 42/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.986 total time=  22.0s\n",
      "[CV 5/5; 43/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 43/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.940 total time=   4.9s\n",
      "[CV 5/5; 44/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 44/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.973 total time=  13.4s\n",
      "[CV 5/5; 45/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 45/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.985 total time=  24.2s\n",
      "[CV 1/5; 47/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 47/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.843 total time=  13.3s\n",
      "[CV 1/5; 48/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 48/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.844 total time=  22.7s\n",
      "[CV 1/5; 49/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 49/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.830 total time=   4.8s\n",
      "[CV 1/5; 50/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 50/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.843 total time=  13.6s\n",
      "[CV 1/5; 51/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 51/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.844 total time=  24.2s\n",
      "[CV 2/5; 52/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 52/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.937 total time=   5.3s\n",
      "[CV 2/5; 53/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 53/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.973 total time=  13.6s\n",
      "[CV 2/5; 54/162] START bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 54/162] END bagging_fraction=0.6, learning_rate=0.015, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.987 total time=  22.7s\n",
      "[CV 2/5; 55/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 55/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.882 total time=   4.3s\n",
      "[CV 2/5; 56/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 56/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.897 total time=  12.5s\n",
      "[CV 2/5; 57/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 57/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.920 total time=  22.4s\n",
      "[CV 2/5; 58/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 58/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.882 total time=   4.3s\n",
      "[CV 2/5; 59/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 59/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.897 total time=  13.3s\n",
      "[CV 3/5; 60/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 60/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.919 total time=  20.2s\n",
      "[CV 2/5; 61/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 61/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.882 total time=   4.3s\n",
      "[CV 2/5; 62/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 62/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.897 total time=  12.1s\n",
      "[CV 2/5; 63/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 63/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.920 total time=  20.0s\n",
      "[CV 2/5; 64/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 64/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.921 total time=   4.8s\n",
      "[CV 2/5; 65/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 65/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.936 total time=  13.1s\n",
      "[CV 2/5; 66/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 66/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.949 total time=  21.9s\n",
      "[CV 1/5; 67/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 67/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.820 total time=   4.8s\n",
      "[CV 4/5; 67/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 67/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.920 total time=   4.7s\n",
      "[CV 3/5; 68/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 68/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.936 total time=  13.3s\n",
      "[CV 3/5; 69/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 69/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.950 total time=  22.2s\n",
      "[CV 3/5; 70/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 70/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.921 total time=   4.8s\n",
      "[CV 3/5; 71/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 71/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.936 total time=  13.3s\n",
      "[CV 3/5; 72/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 72/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.950 total time=  22.6s\n",
      "[CV 3/5; 73/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 73/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.921 total time=   6.2s\n",
      "[CV 3/5; 74/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 74/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.938 total time=  15.3s\n",
      "[CV 3/5; 75/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 75/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.951 total time=  23.3s\n",
      "[CV 3/5; 76/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 76/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.921 total time=   4.8s\n",
      "[CV 2/5; 77/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 77/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.936 total time=  13.8s\n",
      "[CV 2/5; 78/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 78/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.950 total time=  22.9s\n",
      "[CV 2/5; 79/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 79/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.921 total time=   4.9s\n",
      "[CV 2/5; 80/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 80/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.936 total time=  15.0s\n",
      "[CV 3/5; 81/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 81/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.951 total time=  22.8s\n",
      "[CV 2/5; 82/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 82/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.922 total time=   4.6s\n",
      "[CV 2/5; 83/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 83/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.974 total time=  12.2s\n",
      "[CV 2/5; 84/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 84/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.985 total time=  18.7s\n",
      "[CV 2/5; 85/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 85/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.922 total time=   4.5s\n",
      "[CV 2/5; 86/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 86/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.975 total time=  11.8s\n",
      "[CV 2/5; 87/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 87/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  19.8s\n",
      "[CV 2/5; 88/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 88/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.922 total time=   4.5s\n",
      "[CV 2/5; 89/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 89/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.974 total time=  12.0s\n",
      "[CV 2/5; 90/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 90/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.985 total time=  21.4s\n",
      "[CV 2/5; 91/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 91/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.950 total time=   4.9s\n",
      "[CV 2/5; 92/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 92/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.984 total time=  13.9s\n",
      "[CV 2/5; 93/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 93/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.989 total time=  21.2s\n",
      "[CV 2/5; 94/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 94/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.950 total time=   5.0s\n",
      "[CV 2/5; 95/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 95/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.985 total time=  13.9s\n",
      "[CV 2/5; 96/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 96/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  21.2s\n",
      "[CV 1/5; 97/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 97/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.839 total time=   5.1s\n",
      "[CV 1/5; 98/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[CV 3/5; 65/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 65/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.936 total time=  13.3s\n",
      "[CV 3/5; 66/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 66/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.950 total time=  22.2s\n",
      "[CV 3/5; 67/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 67/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.921 total time=   5.1s\n",
      "[CV 4/5; 68/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 68/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.936 total time=  13.3s\n",
      "[CV 4/5; 69/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 69/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.950 total time=  22.3s\n",
      "[CV 4/5; 70/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 70/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.920 total time=   5.1s\n",
      "[CV 4/5; 71/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 71/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.936 total time=  14.4s\n",
      "[CV 5/5; 72/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 72/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.951 total time=  25.4s\n",
      "[CV 1/5; 74/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 74/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.832 total time=  16.4s\n",
      "[CV 1/5; 75/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 75/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.839 total time=  23.1s\n",
      "[CV 1/5; 76/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 76/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.820 total time=   4.9s\n",
      "[CV 1/5; 77/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 77/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.832 total time=  13.6s\n",
      "[CV 1/5; 78/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 78/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.839 total time=  22.8s\n",
      "[CV 1/5; 79/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 79/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.820 total time=   5.2s\n",
      "[CV 1/5; 80/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 80/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.832 total time=  13.7s\n",
      "[CV 1/5; 81/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 81/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.839 total time=  22.3s\n",
      "[CV 1/5; 82/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 82/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.827 total time=   4.8s\n",
      "[CV 5/5; 82/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 82/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.919 total time=   4.9s\n",
      "[CV 5/5; 83/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 83/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.976 total time=  13.1s\n",
      "[CV 5/5; 84/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 84/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.985 total time=  18.5s\n",
      "[CV 5/5; 85/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 85/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.919 total time=   4.6s\n",
      "[CV 5/5; 86/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 86/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.976 total time=  11.7s\n",
      "[CV 5/5; 87/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 87/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  18.4s\n",
      "[CV 1/5; 89/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 89/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.842 total time=  11.8s\n",
      "[CV 1/5; 90/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 90/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.843 total time=  20.4s\n",
      "[CV 1/5; 91/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 91/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.839 total time=   5.5s\n",
      "[CV 4/5; 91/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 91/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.950 total time=   5.1s\n",
      "[CV 4/5; 92/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 92/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.986 total time=  13.9s\n",
      "[CV 4/5; 93/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 93/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  21.3s\n",
      "[CV 4/5; 94/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 94/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.950 total time=   5.1s\n",
      "[CV 3/5; 95/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 95/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.985 total time=  13.9s\n",
      "[CV 3/5; 96/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 96/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  23.0s\n",
      "[CV 4/5; 97/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[CV 4/5; 65/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 65/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.936 total time=  14.3s\n",
      "[CV 4/5; 66/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 66/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.950 total time=  23.9s\n",
      "[CV 1/5; 68/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 68/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.830 total time=  13.2s\n",
      "[CV 1/5; 69/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 69/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.839 total time=  21.7s\n",
      "[CV 1/5; 70/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 70/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.820 total time=   4.7s\n",
      "[CV 1/5; 71/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 71/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.830 total time=  13.1s\n",
      "[CV 1/5; 72/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 72/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.839 total time=  21.6s\n",
      "[CV 1/5; 73/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5; 73/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.820 total time=   5.4s\n",
      "[CV 5/5; 73/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 73/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.925 total time=   6.1s\n",
      "[CV 5/5; 74/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 74/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.939 total time=  14.8s\n",
      "[CV 5/5; 75/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 75/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.953 total time=  23.3s\n",
      "[CV 5/5; 76/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 76/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.925 total time=   5.2s\n",
      "[CV 5/5; 77/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 77/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.939 total time=  13.7s\n",
      "[CV 5/5; 78/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 78/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.953 total time=  25.0s\n",
      "[CV 5/5; 79/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 79/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.925 total time=   4.9s\n",
      "[CV 5/5; 80/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 80/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.939 total time=  15.0s\n",
      "[CV 5/5; 81/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 81/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.953 total time=  22.8s\n",
      "[CV 1/5; 83/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 83/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.842 total time=  11.9s\n",
      "[CV 1/5; 84/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 84/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.842 total time=  19.6s\n",
      "[CV 1/5; 85/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 85/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.827 total time=   4.6s\n",
      "[CV 1/5; 86/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 86/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.841 total time=  11.5s\n",
      "[CV 1/5; 87/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 87/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.843 total time=  17.8s\n",
      "[CV 1/5; 88/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 88/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.827 total time=   4.5s\n",
      "[CV 5/5; 88/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 88/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.919 total time=   5.0s\n",
      "[CV 5/5; 89/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 89/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.976 total time=  12.9s\n",
      "[CV 5/5; 90/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 90/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.985 total time=  21.0s\n",
      "[CV 1/5; 92/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 92/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.843 total time=  13.6s\n",
      "[CV 1/5; 93/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 93/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.846 total time=  21.5s\n",
      "[CV 1/5; 94/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 94/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.839 total time=   5.5s\n",
      "[CV 5/5; 94/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 94/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.951 total time=   5.1s\n",
      "[CV 5/5; 95/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 95/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.986 total time=  15.0s\n",
      "[CV 5/5; 96/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 96/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  21.4s\n",
      "[CV 5/5; 97/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[CV 5/5; 66/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 66/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.951 total time=  22.1s\n",
      "[CV 5/5; 67/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 67/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.925 total time=   4.7s\n",
      "[CV 5/5; 68/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 68/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.939 total time=  13.2s\n",
      "[CV 5/5; 69/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 69/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.951 total time=  22.1s\n",
      "[CV 5/5; 70/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 70/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.925 total time=   4.8s\n",
      "[CV 5/5; 71/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5; 71/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.939 total time=  13.3s\n",
      "[CV 4/5; 72/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 72/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.950 total time=  22.6s\n",
      "[CV 4/5; 73/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 73/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.920 total time=   6.5s\n",
      "[CV 4/5; 74/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 74/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.937 total time=  14.9s\n",
      "[CV 4/5; 75/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 75/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.951 total time=  23.4s\n",
      "[CV 4/5; 76/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 76/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.920 total time=   4.8s\n",
      "[CV 4/5; 77/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 77/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.937 total time=  13.7s\n",
      "[CV 4/5; 78/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 78/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.951 total time=  25.0s\n",
      "[CV 4/5; 79/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 79/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.920 total time=   4.9s\n",
      "[CV 4/5; 80/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 80/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.937 total time=  13.8s\n",
      "[CV 4/5; 81/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5; 81/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.951 total time=  22.9s\n",
      "[CV 4/5; 82/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 82/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.920 total time=   4.6s\n",
      "[CV 4/5; 83/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 83/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.976 total time=  13.0s\n",
      "[CV 4/5; 84/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 84/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.985 total time=  18.5s\n",
      "[CV 4/5; 85/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 85/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.920 total time=   4.6s\n",
      "[CV 4/5; 86/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 86/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.976 total time=  11.6s\n",
      "[CV 4/5; 87/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 87/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.986 total time=  18.5s\n",
      "[CV 3/5; 88/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 88/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.919 total time=   4.5s\n",
      "[CV 3/5; 89/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 89/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.976 total time=  12.1s\n",
      "[CV 3/5; 90/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 90/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.985 total time=  21.3s\n",
      "[CV 3/5; 91/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 91/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.950 total time=   5.4s\n",
      "[CV 3/5; 92/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 92/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.986 total time=  14.0s\n",
      "[CV 3/5; 93/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 93/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.991 total time=  21.4s\n",
      "[CV 3/5; 94/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 94/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.950 total time=   5.4s\n",
      "[CV 4/5; 95/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 95/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.986 total time=  13.8s\n",
      "[CV 4/5; 96/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 96/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  21.3s\n",
      "[CV 3/5; 97/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 97/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.950 total time=   5.0s\n",
      "[CV 3/5; 98/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[CV 2/5; 67/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 67/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.921 total time=   5.1s\n",
      "[CV 2/5; 68/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 68/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.936 total time=  13.2s\n",
      "[CV 2/5; 69/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 69/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.949 total time=  22.2s\n",
      "[CV 2/5; 70/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 70/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.921 total time=   4.7s\n",
      "[CV 2/5; 71/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 71/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.936 total time=  13.3s\n",
      "[CV 2/5; 72/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 72/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.949 total time=  22.6s\n",
      "[CV 2/5; 73/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 73/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.921 total time=   5.6s\n",
      "[CV 2/5; 74/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 74/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.936 total time=  16.5s\n",
      "[CV 2/5; 75/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 75/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.950 total time=  23.2s\n",
      "[CV 2/5; 76/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 76/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.921 total time=   5.2s\n",
      "[CV 3/5; 77/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 77/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.938 total time=  13.8s\n",
      "[CV 3/5; 78/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 78/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.951 total time=  23.1s\n",
      "[CV 3/5; 79/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 79/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.921 total time=   4.9s\n",
      "[CV 3/5; 80/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5; 80/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.938 total time=  13.9s\n",
      "[CV 2/5; 81/162] START bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5; 81/162] END bagging_fraction=0.6, learning_rate=0.005, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.950 total time=  24.8s\n",
      "[CV 3/5; 82/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 82/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.919 total time=   4.6s\n",
      "[CV 3/5; 83/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 83/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.976 total time=  12.2s\n",
      "[CV 3/5; 84/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 84/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.986 total time=  18.9s\n",
      "[CV 3/5; 85/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 85/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.919 total time=   4.5s\n",
      "[CV 3/5; 86/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 86/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.976 total time=  11.7s\n",
      "[CV 3/5; 87/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 87/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.986 total time=  19.9s\n",
      "[CV 4/5; 88/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 88/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.920 total time=   4.6s\n",
      "[CV 4/5; 89/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 89/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.976 total time=  13.0s\n",
      "[CV 4/5; 90/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 90/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.986 total time=  21.0s\n",
      "[CV 5/5; 91/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 91/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.951 total time=   5.0s\n",
      "[CV 5/5; 92/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 92/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.986 total time=  15.2s\n",
      "[CV 5/5; 93/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 93/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  21.4s\n",
      "[CV 1/5; 95/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 95/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.844 total time=  14.6s\n",
      "[CV 1/5; 96/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 96/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.847 total time=  23.2s\n",
      "[CV 2/5; 97/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 97/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.950 total time=   5.4s\n",
      "[CV 2/5; 98/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 98/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.985 total time=  13.8s\n",
      "[CV 2/5; 99/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 99/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  20.9s\n",
      "[CV 2/5; 100/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 98/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.844 total time=  13.4s\n",
      "[CV 1/5; 99/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 99/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.847 total time=  21.2s\n",
      "[CV 1/5; 100/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 100/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.839 total time=   4.9s\n",
      "[CV 5/5; 100/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 100/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.953 total time=   4.9s\n",
      "[CV 5/5; 101/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 101/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.988 total time=  13.9s\n",
      "[CV 4/5; 102/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 102/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  20.9s\n",
      "[CV 3/5; 103/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 103/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.952 total time=   5.0s\n",
      "[CV 3/5; 104/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 104/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.988 total time=  13.9s\n",
      "[CV 3/5; 105/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 105/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.991 total time=  23.6s\n",
      "[CV 5/5; 106/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 106/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.953 total time=   4.9s\n",
      "[CV 5/5; 107/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 107/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.988 total time=  13.8s\n",
      "[CV 5/5; 108/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 108/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  20.7s\n",
      "[CV 3/5; 109/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 109/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.898 total time=   4.3s\n",
      "[CV 3/5; 110/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 110/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.963 total time=  12.0s\n",
      "[CV 2/5; 111/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 111/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.975 total time=  20.7s\n",
      "[CV 4/5; 112/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 112/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.897 total time=   4.4s\n",
      "[CV 4/5; 113/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 113/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.964 total time=  12.1s\n",
      "[CV 4/5; 114/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 114/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.976 total time=  19.1s\n",
      "[CV 4/5; 115/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 115/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.897 total time=   4.4s\n",
      "[CV 4/5; 116/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 116/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.964 total time=  11.8s\n",
      "[CV 4/5; 117/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 117/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.976 total time=  19.3s\n",
      "[CV 4/5; 118/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 118/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.935 total time=   4.8s\n",
      "[CV 3/5; 119/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 119/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.973 total time=  13.4s\n",
      "[CV 3/5; 120/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 120/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.986 total time=  22.7s\n",
      "[CV 3/5; 121/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 121/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.938 total time=   4.7s\n",
      "[CV 2/5; 122/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 122/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.972 total time=  13.6s\n",
      "[CV 2/5; 123/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 123/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  22.0s\n",
      "[CV 2/5; 124/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 124/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.935 total time=   5.3s\n",
      "[CV 2/5; 125/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 125/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.972 total time=  13.8s\n",
      "[CV 2/5; 126/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 126/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.984 total time=  22.3s\n",
      "[CV 2/5; 127/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 127/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.937 total time=   4.8s\n",
      "[CV 2/5; 128/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 128/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.973 total time=  13.4s\n",
      "[CV 2/5; 129/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 97/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.950 total time=   5.4s\n",
      "[CV 4/5; 98/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 98/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.986 total time=  13.7s\n",
      "[CV 4/5; 99/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 99/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  20.9s\n",
      "[CV 3/5; 100/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 100/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.952 total time=   4.9s\n",
      "[CV 3/5; 101/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 101/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.988 total time=  13.9s\n",
      "[CV 3/5; 102/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 102/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.991 total time=  22.7s\n",
      "[CV 5/5; 103/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 103/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.953 total time=   5.0s\n",
      "[CV 5/5; 104/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 104/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.988 total time=  13.8s\n",
      "[CV 4/5; 105/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 105/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  21.9s\n",
      "[CV 1/5; 106/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 106/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.839 total time=   4.9s\n",
      "[CV 2/5; 107/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 107/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.987 total time=  13.8s\n",
      "[CV 1/5; 108/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 108/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.847 total time=  23.1s\n",
      "[CV 5/5; 109/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 109/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.899 total time=   4.8s\n",
      "[CV 5/5; 110/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 110/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.963 total time=  12.8s\n",
      "[CV 5/5; 111/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 111/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.976 total time=  18.9s\n",
      "[CV 5/5; 112/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 112/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.899 total time=   4.5s\n",
      "[CV 5/5; 113/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 113/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.963 total time=  12.0s\n",
      "[CV 5/5; 114/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 114/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.976 total time=  19.0s\n",
      "[CV 5/5; 115/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 115/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.899 total time=   4.4s\n",
      "[CV 5/5; 116/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 116/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.963 total time=  12.6s\n",
      "[CV 5/5; 117/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 117/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.976 total time=  19.1s\n",
      "[CV 5/5; 118/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 118/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.940 total time=   4.7s\n",
      "[CV 5/5; 119/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 119/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.973 total time=  13.3s\n",
      "[CV 5/5; 120/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 120/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.986 total time=  22.7s\n",
      "[CV 4/5; 121/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 121/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.935 total time=   4.8s\n",
      "[CV 4/5; 122/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 122/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.973 total time=  14.7s\n",
      "[CV 4/5; 123/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 123/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.986 total time=  22.3s\n",
      "[CV 4/5; 124/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 124/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.935 total time=   5.2s\n",
      "[CV 4/5; 125/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 125/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.973 total time=  13.5s\n",
      "[CV 4/5; 126/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 126/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.986 total time=  22.1s\n",
      "[CV 4/5; 127/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 127/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.935 total time=   4.8s\n",
      "[CV 4/5; 128/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 128/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.975 total time=  13.4s\n",
      "[CV 4/5; 129/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 97/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.951 total time=   5.4s\n",
      "[CV 5/5; 98/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 98/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.985 total time=  13.8s\n",
      "[CV 5/5; 99/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 99/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  22.4s\n",
      "[CV 2/5; 101/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 101/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.987 total time=  13.8s\n",
      "[CV 2/5; 102/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 102/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  22.5s\n",
      "[CV 1/5; 103/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 103/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.839 total time=   5.0s\n",
      "[CV 1/5; 104/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 104/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.845 total time=  14.0s\n",
      "[CV 1/5; 105/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 105/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.847 total time=  24.4s\n",
      "[CV 4/5; 106/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 106/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.951 total time=   4.9s\n",
      "[CV 4/5; 107/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 107/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.988 total time=  13.9s\n",
      "[CV 4/5; 108/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 108/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  20.8s\n",
      "[CV 2/5; 109/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 109/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.897 total time=   4.3s\n",
      "[CV 2/5; 110/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 110/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.962 total time=  13.0s\n",
      "[CV 3/5; 111/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 111/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.975 total time=  19.2s\n",
      "[CV 2/5; 112/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 112/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.897 total time=   4.4s\n",
      "[CV 2/5; 113/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 113/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.962 total time=  12.2s\n",
      "[CV 1/5; 114/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 114/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.842 total time=  18.7s\n",
      "[CV 1/5; 115/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 115/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.817 total time=   4.3s\n",
      "[CV 1/5; 116/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 116/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.843 total time=  12.6s\n",
      "[CV 1/5; 117/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 117/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.842 total time=  18.8s\n",
      "[CV 1/5; 118/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 118/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.830 total time=   4.8s\n",
      "[CV 1/5; 119/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 119/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.842 total time=  13.2s\n",
      "[CV 1/5; 120/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 120/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.843 total time=  22.0s\n",
      "[CV 1/5; 121/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 121/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.830 total time=   5.1s\n",
      "[CV 1/5; 122/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 122/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.842 total time=  13.3s\n",
      "[CV 1/5; 123/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 123/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.843 total time=  21.1s\n",
      "[CV 1/5; 124/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 124/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.830 total time=   5.4s\n",
      "[CV 5/5; 124/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 124/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.940 total time=   5.5s\n",
      "[CV 5/5; 125/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 125/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.973 total time=  14.7s\n",
      "[CV 5/5; 126/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 126/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.985 total time=  22.2s\n",
      "[CV 5/5; 127/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 127/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.940 total time=   4.8s\n",
      "[CV 5/5; 128/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 128/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.974 total time=  13.5s\n",
      "[CV 5/5; 129/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 98/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.985 total time=  13.7s\n",
      "[CV 3/5; 99/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 99/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.991 total time=  22.7s\n",
      "[CV 4/5; 100/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 100/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.951 total time=   4.9s\n",
      "[CV 4/5; 101/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 101/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.988 total time=  15.1s\n",
      "[CV 5/5; 102/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 102/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.990 total time=  20.9s\n",
      "[CV 4/5; 103/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 103/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.951 total time=   5.4s\n",
      "[CV 4/5; 104/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 104/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.988 total time=  13.9s\n",
      "[CV 5/5; 105/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 105/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  22.1s\n",
      "[CV 3/5; 106/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 106/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.952 total time=   4.9s\n",
      "[CV 3/5; 107/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 107/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.988 total time=  13.8s\n",
      "[CV 3/5; 108/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 108/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.990 total time=  20.7s\n",
      "[CV 1/5; 109/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 109/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.817 total time=   4.3s\n",
      "[CV 1/5; 110/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 110/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.843 total time=  11.9s\n",
      "[CV 1/5; 111/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 111/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.842 total time=  20.0s\n",
      "[CV 1/5; 112/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 112/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.817 total time=   4.4s\n",
      "[CV 1/5; 113/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 113/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.843 total time=  13.1s\n",
      "[CV 2/5; 114/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 114/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.974 total time=  19.3s\n",
      "[CV 2/5; 115/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 115/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.897 total time=   4.5s\n",
      "[CV 3/5; 116/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 116/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.963 total time=  11.9s\n",
      "[CV 2/5; 117/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 117/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.975 total time=  19.4s\n",
      "[CV 2/5; 118/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 118/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.935 total time=   4.7s\n",
      "[CV 2/5; 119/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 119/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.972 total time=  13.3s\n",
      "[CV 2/5; 120/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 120/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.985 total time=  24.5s\n",
      "[CV 5/5; 121/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 121/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.940 total time=   4.8s\n",
      "[CV 5/5; 122/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 122/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.973 total time=  14.7s\n",
      "[CV 5/5; 123/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5; 123/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  22.4s\n",
      "[CV 1/5; 125/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 125/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.842 total time=  13.7s\n",
      "[CV 1/5; 126/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 126/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.843 total time=  23.5s\n",
      "[CV 1/5; 127/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 127/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.830 total time=   5.2s\n",
      "[CV 1/5; 128/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 128/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.843 total time=  13.3s\n",
      "[CV 1/5; 129/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 129/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.844 total time=  22.6s\n",
      "[CV 1/5; 130/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 130/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.830 total time=   4.8s\n",
      "[CV 5/5; 130/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 100/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.950 total time=   4.8s\n",
      "[CV 1/5; 101/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 101/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.845 total time=  14.0s\n",
      "[CV 1/5; 102/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 102/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.847 total time=  23.3s\n",
      "[CV 2/5; 103/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 103/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.950 total time=   5.0s\n",
      "[CV 2/5; 104/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 104/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.987 total time=  13.8s\n",
      "[CV 2/5; 105/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 105/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=5, n_estimators=500;, score=0.990 total time=  23.4s\n",
      "[CV 2/5; 106/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 106/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=100;, score=0.950 total time=   4.9s\n",
      "[CV 1/5; 107/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 107/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=300;, score=0.845 total time=  13.9s\n",
      "[CV 2/5; 108/162] START bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 108/162] END bagging_fraction=0.8, learning_rate=0.025, max_depth=15, min_data_in_leaf=10, n_estimators=500;, score=0.989 total time=  22.2s\n",
      "[CV 4/5; 109/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 109/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=100;, score=0.897 total time=   4.7s\n",
      "[CV 4/5; 110/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 110/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=300;, score=0.964 total time=  12.0s\n",
      "[CV 4/5; 111/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 111/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=1, n_estimators=500;, score=0.976 total time=  19.1s\n",
      "[CV 3/5; 112/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 112/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=100;, score=0.898 total time=   4.4s\n",
      "[CV 3/5; 113/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 113/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=300;, score=0.963 total time=  12.2s\n",
      "[CV 3/5; 114/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 114/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=5, n_estimators=500;, score=0.975 total time=  19.3s\n",
      "[CV 3/5; 115/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 115/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=100;, score=0.898 total time=   4.4s\n",
      "[CV 2/5; 116/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 116/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=300;, score=0.962 total time=  11.9s\n",
      "[CV 3/5; 117/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 117/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=5, min_data_in_leaf=10, n_estimators=500;, score=0.975 total time=  19.3s\n",
      "[CV 3/5; 118/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 118/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=100;, score=0.938 total time=   4.8s\n",
      "[CV 4/5; 119/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 119/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=300;, score=0.973 total time=  13.4s\n",
      "[CV 4/5; 120/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5; 120/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=1, n_estimators=500;, score=0.986 total time=  22.7s\n",
      "[CV 2/5; 121/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 121/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=100;, score=0.935 total time=   5.2s\n",
      "[CV 3/5; 122/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 122/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=300;, score=0.973 total time=  13.7s\n",
      "[CV 3/5; 123/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 123/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=5, n_estimators=500;, score=0.985 total time=  21.9s\n",
      "[CV 3/5; 124/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 124/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=100;, score=0.938 total time=   5.3s\n",
      "[CV 3/5; 125/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 125/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=300;, score=0.973 total time=  13.8s\n",
      "[CV 3/5; 126/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 126/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=10, min_data_in_leaf=10, n_estimators=500;, score=0.986 total time=  22.3s\n",
      "[CV 3/5; 127/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 127/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=100;, score=0.939 total time=   5.1s\n",
      "[CV 3/5; 128/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 128/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=300;, score=0.975 total time=  13.5s\n",
      "[CV 3/5; 129/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5; 129/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=1, n_estimators=500;, score=0.988 total time=  22.6s\n",
      "[CV 2/5; 130/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5; 130/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=100;, score=0.937 total time=   4.8s\n",
      "[CV 1/5; 131/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5; 131/162] END bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=300;, score=0.843 total time=  14.6s\n",
      "[CV 3/5; 132/162] START bagging_fraction=0.8, learning_rate=0.015, max_depth=15, min_data_in_leaf=5, n_estimators=500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LGBMClassifier(metric=&#x27;auc&#x27;), n_jobs=5,\n",
       "             param_grid={&#x27;bagging_fraction&#x27;: [0.6, 0.8],\n",
       "                         &#x27;learning_rate&#x27;: [0.025, 0.015, 0.005],\n",
       "                         &#x27;max_depth&#x27;: [5, 10, 15],\n",
       "                         &#x27;min_data_in_leaf&#x27;: [1, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "             verbose=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LGBMClassifier(metric=&#x27;auc&#x27;), n_jobs=5,\n",
       "             param_grid={&#x27;bagging_fraction&#x27;: [0.6, 0.8],\n",
       "                         &#x27;learning_rate&#x27;: [0.025, 0.015, 0.005],\n",
       "                         &#x27;max_depth&#x27;: [5, 10, 15],\n",
       "                         &#x27;min_data_in_leaf&#x27;: [1, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "             verbose=11)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LGBMClassifier(metric='auc'), n_jobs=5,\n",
       "             param_grid={'bagging_fraction': [0.6, 0.8],\n",
       "                         'learning_rate': [0.025, 0.015, 0.005],\n",
       "                         'max_depth': [5, 10, 15],\n",
       "                         'min_data_in_leaf': [1, 5, 10],\n",
       "                         'n_estimators': [100, 300, 500]},\n",
       "             verbose=11)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(metric='auc')\n",
    "parameters = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'learning_rate':[0.025, 0.015,0.005],\n",
    "    'max_depth' :[5, 10, 15],\n",
    "    'min_data_in_leaf':[1, 5, 10],\n",
    "    'bagging_fraction': [0.6, 0.8],\n",
    "}\n",
    "\n",
    "gsearch = GridSearchCV(clf, param_grid = parameters, n_jobs=5, verbose=11)\n",
    "gsearch.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.6, 'learning_rate': 0.025, 'max_depth': 15, 'min_data_in_leaf': 1, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print(gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(n_estimator=500, learning_rate = 0.025, max_depth = 15, min_data_in_leaf = 1, \n",
    "                         bagging_fraction = 0.6, subsample=0.9, metric='auc')\n",
    "\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_test_predicted = clf.predict_proba(test)[:,1]\n",
    "\n",
    "result = pd.read_csv('data/sampleEntry.csv') \n",
    "result['Probability'] = y_test_predicted\n",
    "result.to_csv('data/submit6.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The private score for this model is 0.863, which is very close to the top answers on Kaggle.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, with the input data, I first conducted EDA with summary statistics and visualizations. Then, in the data pre-processing stages, I removed the outliers from our dataset, replaced the missing values with values from its nearest neighbors, and standardized all the input features. In the data anlaysis stage, I first tried to fit a logitic regression without considering the interaction effects between the predictors with 8-fold cross validation. The testing AUC is 0.84, while its private performance score on Kaggle is 0.766. \n",
    "\n",
    "Some key take-aways for decision makers are: \n",
    "1. Younger people are more likely to experience 90 days past due delinquency or worse. \n",
    "2. Borrower who have past due for no more than 59 days, 60-89 days, or over 90 days are more frequently are more likely to experience 90 days past due delinquency or worse. \n",
    "3. Monthly income, debt ratio, and number of dependents don't have a significant effect on our response variables.\n",
    "\n",
    "In other words, younger people and people who have past due at the past are more likely to experience 90 days past due delinquency or worse. \n",
    "\n",
    "Then, I tried to consider the interaction effects between the predictors by constructing a polynomial logistic regression with up to 2 degrees. Even though the testing AUC improves by 0.005, its private performance score drops by 0.013. Therefore, it might not be a good idea to fit a polynomial logistic regression model on our data set. The potential problem could be overfitting.\n",
    "\n",
    "Then, I fitted a series of random forests models with `RandomForestClassier` and 5-fold crossvalidation. I used a search grid to alter the parameters for `max_depth`, `min_samples_leaf`, `min_samples_split`, and `n_estimators` for hyperparameter tuning. The private score on Kaggle is 0.856. Compared to logistic regression, this is a big improvement. \n",
    "\n",
    "Lastly, I fitted light GBM models on the data set. After hyperparameter tuning, the final model has a private score of 0.863, which is a further improvement compared to the previous two methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Currently, I just explored the given features. More insights might be drawn if feature engineering has been conducted. For exmaple, we can get the monthly debt by multiplying monthlyincome with debtratio. The resulting monthly debt might gives us a better understanding of borrowers' behaviors. \n",
    "\n",
    "- Due to time limitation, there are other supervised learning models I would like to explore: \n",
    "1. XGBoost \n",
    "2. Support Vector Machine (SVM)\n",
    "3. Naive Bayes. \n",
    "\n",
    "- To further improve my logistic regression model and random forest model, I should construct confusion matrix for my models in order to investigate if my model have high false positive rate or false negative rate. In this way, I can better improve my model through regularization and hyperparameter tuning. \n",
    "\n",
    "- The pre-processing can be improved as well. Currently, it's only a heurisitic to drop all the observations having more than 2 features as an outlier. Another way is to decide how to drop outliers for each feature separately. \n",
    "\n",
    "- Some pitfalls I encountered: \n",
    "1. It's better to use unscaled data as input for random forest and light GBM. However, other methods like logistic regression assumes the inputs have been scaled. \n",
    "2. Polynomial logistic regression fails to converge error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
